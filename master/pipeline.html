

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Processing Pipeline &mdash; Rasa NLU 10.12.3+project_manager.worker_interfaces documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="_static/banner.css" type="text/css" />
  
    <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="genindex.html"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="Rasa NLU 10.12.3+project_manager.worker_interfaces documentation" href="index.html"/>
        <link rel="next" title="Evaluation" href="evaluation.html"/>
        <link rel="prev" title="Language Support" href="languages.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> Rasa NLU
          

          
          </a>

          
            
            
              <div class="version">
                10.12
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial.html">Tutorial: A simple restaurant search bot</a></li>
</ul>
<p class="caption"><span class="caption-text">User Documentation</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="config.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="migrating.html">Migrating an existing app</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataformat.html">Training and Data Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="http.html">Using Rasa NLU as a HTTP server</a></li>
<li class="toctree-l1"><a class="reference internal" href="python.html">Using Rasa NLU from python</a></li>
<li class="toctree-l1"><a class="reference internal" href="entities.html">Entity Extraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="closeloop.html">Improving your models from feedback</a></li>
<li class="toctree-l1"><a class="reference internal" href="persist.html">Model Persistence</a></li>
<li class="toctree-l1"><a class="reference internal" href="languages.html">Language Support</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Processing Pipeline</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#pre-configured-pipelines">Pre-configured Pipelines</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#spacy-sklearn">spacy_sklearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mitie">mitie</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mitie-sklearn">mitie_sklearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="#keyword">keyword</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tensorflow-embedding">tensorflow_embedding</a></li>
<li class="toctree-l3"><a class="reference internal" href="#custom-pipelines">Custom pipelines</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#built-in-components">Built-in Components</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#nlp-mitie">nlp_mitie</a></li>
<li class="toctree-l3"><a class="reference internal" href="#nlp-spacy">nlp_spacy</a></li>
<li class="toctree-l3"><a class="reference internal" href="#intent-featurizer-mitie">intent_featurizer_mitie</a></li>
<li class="toctree-l3"><a class="reference internal" href="#intent-featurizer-spacy">intent_featurizer_spacy</a></li>
<li class="toctree-l3"><a class="reference internal" href="#intent-featurizer-ngrams">intent_featurizer_ngrams</a></li>
<li class="toctree-l3"><a class="reference internal" href="#intent-featurizer-count-vectors">intent_featurizer_count_vectors</a></li>
<li class="toctree-l3"><a class="reference internal" href="#intent-classifier-keyword">intent_classifier_keyword</a></li>
<li class="toctree-l3"><a class="reference internal" href="#intent-classifier-mitie">intent_classifier_mitie</a></li>
<li class="toctree-l3"><a class="reference internal" href="#intent-classifier-sklearn">intent_classifier_sklearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="#intent-classifier-tensorflow-embedding">intent_classifier_tensorflow_embedding</a></li>
<li class="toctree-l3"><a class="reference internal" href="#intent-entity-featurizer-regex">intent_entity_featurizer_regex</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tokenizer-whitespace">tokenizer_whitespace</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tokenizer-jieba">tokenizer_jieba</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tokenizer-mitie">tokenizer_mitie</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tokenizer-spacy">tokenizer_spacy</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ner-mitie">ner_mitie</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ner-spacy">ner_spacy</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ner-synonyms">ner_synonyms</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ner-crf">ner_crf</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ner-duckling">ner_duckling</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#creating-new-components">Creating new Components</a></li>
<li class="toctree-l2"><a class="reference internal" href="#component-lifecycle">Component Lifecycle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="evaluation.html">Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="context.html">Context-aware Dialogue</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="migrations.html">Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="license.html">License</a></li>
</ul>
<p class="caption"><span class="caption-text">Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="community.html">Community Contributions</a></li>
</ul>
<p class="caption"><span class="caption-text">Developer Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="contribute.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Change Log</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Rasa NLU</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Processing Pipeline</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/pipeline.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  





<div class="section" id="processing-pipeline">
<span id="section-pipeline"></span><h1>Processing Pipeline<a class="headerlink" href="#processing-pipeline" title="Permalink to this headline">Â¶</a></h1>
<p>The process of incoming messages is split into different components. These components are executed one after another
in a so called processing pipeline. There are components for entity extraction, for intent classification,
pre-processing and there will be many more in the future.</p>
<p>Each component processes the input and creates an output. The ouput can be used by any component that comes after
this component in the pipeline. There are components which only produce information that is used by other components
in the pipeline and there are other components that produce <code class="docutils literal"><span class="pre">Output</span></code> attributes which will be returned after
the processing has finished. For example, for the sentence <code class="docutils literal"><span class="pre">&quot;I</span> <span class="pre">am</span> <span class="pre">looking</span> <span class="pre">for</span> <span class="pre">Chinese</span> <span class="pre">food&quot;</span></code> the output</p>
<div class="highlight-json"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;text&quot;</span><span class="p">:</span> <span class="s2">&quot;I am looking for Chinese food&quot;</span><span class="p">,</span>
    <span class="nt">&quot;entities&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span><span class="nt">&quot;start&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="nt">&quot;end&quot;</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span> <span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="s2">&quot;chinese&quot;</span><span class="p">,</span> <span class="nt">&quot;entity&quot;</span><span class="p">:</span> <span class="s2">&quot;cuisine&quot;</span><span class="p">,</span> <span class="nt">&quot;extractor&quot;</span><span class="p">:</span> <span class="s2">&quot;ner_crf&quot;</span><span class="p">,</span> <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.864</span><span class="p">}</span>
    <span class="p">],</span>
    <span class="nt">&quot;intent&quot;</span><span class="p">:</span> <span class="p">{</span><span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.6485910906220309</span><span class="p">,</span> <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;restaurant_search&quot;</span><span class="p">},</span>
    <span class="nt">&quot;intent_ranking&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span><span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.6485910906220309</span><span class="p">,</span> <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;restaurant_search&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.1416153159565678</span><span class="p">,</span> <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;affirm&quot;</span><span class="p">}</span>
    <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<p>is created as a combination of the results of the different components in the pre-configured pipeline <code class="docutils literal"><span class="pre">spacy_sklearn</span></code>.
For example, the <code class="docutils literal"><span class="pre">entities</span></code> attribute is created by the <code class="docutils literal"><span class="pre">ner_crf</span></code> component.</p>
<div class="section" id="pre-configured-pipelines">
<h2>Pre-configured Pipelines<a class="headerlink" href="#pre-configured-pipelines" title="Permalink to this headline">Â¶</a></h2>
<p>To ease the burden of coming up with your own processing pipelines, we provide a couple of ready to use templates
which can be used by setting the <code class="docutils literal"><span class="pre">pipeline</span></code> configuration value to the name of the template you want to use.
Here is a list of the <strong>existing templates</strong>:</p>
<div class="section" id="spacy-sklearn">
<h3>spacy_sklearn<a class="headerlink" href="#spacy-sklearn" title="Permalink to this headline">Â¶</a></h3>
<p>To use spacy as a template:</p>
<div class="highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">language</span><span class="p p-Indicator">:</span> <span class="s">&quot;en&quot;</span>

<span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span> <span class="s">&quot;spacy_sklearn&quot;</span>
</pre></div>
</div>
<p>See <a class="reference internal" href="languages.html#section-languages"><span class="std std-ref">Language Support</span></a> for possible values for <code class="docutils literal"><span class="pre">language</span></code>. To use
the components and configure them separately:</p>
<div class="highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">language</span><span class="p p-Indicator">:</span> <span class="s">&quot;en&quot;</span>

<span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;nlp_spacy&quot;</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;tokenizer_spacy&quot;</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;intent_entity_featurizer_regex&quot;</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;intent_featurizer_spacy&quot;</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;ner_crf&quot;</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;ner_synonyms&quot;</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;intent_classifier_sklearn&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="mitie">
<h3>mitie<a class="headerlink" href="#mitie" title="Permalink to this headline">Â¶</a></h3>
<p>There is no pipeline template, as you need to configure the location
of mities featurizer. To use the components and configure them separately:</p>
<div class="highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">language</span><span class="p p-Indicator">:</span> <span class="s">&quot;en&quot;</span>

<span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;nlp_mitie&quot;</span>
  <span class="l l-Scalar l-Scalar-Plain">model</span><span class="p p-Indicator">:</span> <span class="s">&quot;data/total_word_feature_extractor.dat&quot;</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;tokenizer_mitie&quot;</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;ner_mitie&quot;</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;ner_synonyms&quot;</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;intent_entity_featurizer_regex&quot;</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;intent_classifier_mitie&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="mitie-sklearn">
<h3>mitie_sklearn<a class="headerlink" href="#mitie-sklearn" title="Permalink to this headline">Â¶</a></h3>
<p>There is no pipeline template, as you need to configure the location
of mities featurizer. To use the components and configure them separately:</p>
<div class="highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">language</span><span class="p p-Indicator">:</span> <span class="s">&quot;en&quot;</span>

<span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;nlp_mitie&quot;</span>
  <span class="l l-Scalar l-Scalar-Plain">model</span><span class="p p-Indicator">:</span> <span class="s">&quot;data/total_word_feature_extractor.dat&quot;</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;tokenizer_mitie&quot;</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;ner_mitie&quot;</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;ner_synonyms&quot;</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;intent_entity_featurizer_regex&quot;</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;intent_featurizer_mitie&quot;</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;intent_classifier_sklearn&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="keyword">
<h3>keyword<a class="headerlink" href="#keyword" title="Permalink to this headline">Â¶</a></h3>
<p>to use it as a template:</p>
<div class="highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">language</span><span class="p p-Indicator">:</span> <span class="s">&quot;en&quot;</span>

<span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span> <span class="s">&quot;keyword&quot;</span>
</pre></div>
</div>
<p>to use the components and configure them separately:</p>
<div class="highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">language</span><span class="p p-Indicator">:</span> <span class="s">&quot;en&quot;</span>

<span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;intent_classifier_keyword&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="tensorflow-embedding">
<h3>tensorflow_embedding<a class="headerlink" href="#tensorflow-embedding" title="Permalink to this headline">Â¶</a></h3>
<p>to use it as a template:</p>
<div class="highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">language</span><span class="p p-Indicator">:</span> <span class="s">&quot;en&quot;</span>

<span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span> <span class="s">&quot;tensorflow_embedding&quot;</span>
</pre></div>
</div>
<p>The tensorflow pipeline supports any language that can be tokenized. The
current tokenizer implementation relies on words being separated by spaces,
so any languages that adheres to that can be trained with this pipeline.</p>
<p>If you want to split intents into multiple labels, e.g. for predicting multiple intents or for modeling hierarchical intent structure, use these flags:</p>
<blockquote>
<div><ul class="simple">
<li><code class="docutils literal"><span class="pre">intent_tokenization_flag</span></code> if <code class="docutils literal"><span class="pre">true</span></code> the algorithm will split the intent labels into tokens and use bag-of-words representations for them;</li>
<li><code class="docutils literal"><span class="pre">intent_split_symbol</span></code> sets the delimiter string to split the intent labels. Default <code class="docutils literal"><span class="pre">_</span></code></li>
</ul>
</div></blockquote>
<p>Here&#8217;s an example configuration:</p>
<div class="highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">language</span><span class="p p-Indicator">:</span> <span class="s">&quot;en&quot;</span>

<span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;intent_featurizer_count_vectors&quot;</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;intent_classifier_tensorflow_embedding&quot;</span>
  <span class="l l-Scalar l-Scalar-Plain">intent_tokenization_flag</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="l l-Scalar l-Scalar-Plain">intent_split_symbol</span><span class="p p-Indicator">:</span> <span class="s">&quot;_&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="custom-pipelines">
<h3>Custom pipelines<a class="headerlink" href="#custom-pipelines" title="Permalink to this headline">Â¶</a></h3>
<p>Creating your own pipelines is possible by directly passing the names of the ~
components to Rasa NLU in the <code class="docutils literal"><span class="pre">pipeline</span></code> configuration variable, e.g.</p>
<div class="highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;nlp_spacy&quot;</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;ner_crf&quot;</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;ner_synonyms&quot;</span>
</pre></div>
</div>
<p>This creates a pipeline that only does entity recognition, but no
intent classification. Hence, the output will not contain any
useful intents.</p>
</div>
</div>
<div class="section" id="built-in-components">
<h2>Built-in Components<a class="headerlink" href="#built-in-components" title="Permalink to this headline">Â¶</a></h2>
<p>Short explanation of every components and it&#8217;s attributes. If you are looking for more details, you should have
a look at the corresponding source code for the component. <code class="docutils literal"><span class="pre">Output</span></code> describes, what each component adds to the final
output result of processing a message. If no output is present, the component is most likely a preprocessor for another
component.</p>
<div class="section" id="nlp-mitie">
<span id="id1"></span><h3>nlp_mitie<a class="headerlink" href="#nlp-mitie" title="Permalink to this headline">Â¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">MITIE initializer</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">nothing</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">Initializes mitie structures. Every mitie component relies on this, hence this should be put at the beginning
of every pipeline that uses any mitie components.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Configuration:</th><td class="field-body"><p class="first">The MITIE library needs a language model file, that <strong>must</strong> be specified in
the configuration:</p>
<div class="highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;nlp_mitie&quot;</span>
  <span class="c1"># language model to load</span>
  <span class="l l-Scalar l-Scalar-Plain">model</span><span class="p p-Indicator">:</span> <span class="s">&quot;data/total_word_feature_extractor.dat&quot;</span>
</pre></div>
</div>
<p class="last">For more information where to get that file from, head over to
<a class="reference internal" href="installation.html#section-backends"><span class="std std-ref">Installation</span></a>.</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="nlp-spacy">
<h3>nlp_spacy<a class="headerlink" href="#nlp-spacy" title="Permalink to this headline">Â¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">spacy language initializer</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">nothing</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">Initializes spacy structures. Every spacy component relies on this, hence this should be put at the beginning
of every pipeline that uses any spacy components.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Configuration:</th><td class="field-body"><p class="first">Language model, default will use the configured language.
If the spacy model to be used has a name that is different from the language tag (<code class="docutils literal"><span class="pre">&quot;en&quot;</span></code>, <code class="docutils literal"><span class="pre">&quot;de&quot;</span></code>, etc.),
the model name can be specified using this configuration variable. The name will be passed to <code class="docutils literal"><span class="pre">spacy.load(name)</span></code>.</p>
<div class="last highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;nlp_spacy&quot;</span>
  <span class="c1"># language model to load</span>
  <span class="l l-Scalar l-Scalar-Plain">model</span><span class="p p-Indicator">:</span> <span class="s">&quot;en_core_web_md&quot;</span>

  <span class="c1"># when retrieving word vectors, this will decide if the casing</span>
  <span class="c1"># of the word is relevant. E.g. `hello` and `Hello` will</span>
  <span class="c1"># retrieve the same vector, if set to `false`. For some</span>
  <span class="c1"># applications and models it makes sense to differentiate</span>
  <span class="c1"># between these two words, therefore setting this to `true`.</span>
  <span class="l l-Scalar l-Scalar-Plain">case_sensitive</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="intent-featurizer-mitie">
<h3>intent_featurizer_mitie<a class="headerlink" href="#intent-featurizer-mitie" title="Permalink to this headline">Â¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">MITIE intent featurizer</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">nothing, used as an input to intent classifiers that need intent features (e.g. <code class="docutils literal"><span class="pre">intent_classifier_sklearn</span></code>)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">Creates feature for intent classification using the MITIE featurizer.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">NOT used by the <code class="docutils literal"><span class="pre">intent_classifier_mitie</span></code> component. Currently, only <code class="docutils literal"><span class="pre">intent_classifier_sklearn</span></code> is able
to use precomputed features.</p>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Configuration:</th><td class="field-body"><div class="first last highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;intent_featurizer_mitie&quot;</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="intent-featurizer-spacy">
<h3>intent_featurizer_spacy<a class="headerlink" href="#intent-featurizer-spacy" title="Permalink to this headline">Â¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body">spacy intent featurizer</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body">nothing, used as an input to intent classifiers that need intent features (e.g. <code class="docutils literal"><span class="pre">intent_classifier_sklearn</span></code>)</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body">Creates feature for intent classification using the spacy featurizer.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="intent-featurizer-ngrams">
<h3>intent_featurizer_ngrams<a class="headerlink" href="#intent-featurizer-ngrams" title="Permalink to this headline">Â¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Appends char-ngram features to feature vector</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">nothing, appends its features to an existing feature vector generated by another intent featurizer</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">This featurizer appends character ngram features to a feature vector. During training the component looks for the
most common character sequences (e.g. <code class="docutils literal"><span class="pre">app</span></code> or <code class="docutils literal"><span class="pre">ing</span></code>). The added features represent a boolean flag if the
character sequence is present in the word sequence or not.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">There needs to be another intent featurizer previous to this one in the pipeline!</p>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Configuration:</th><td class="field-body"><div class="first last highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;intent_featurizer_ngrams&quot;</span>
  <span class="c1"># Maximum number of ngrams to use when augmenting</span>
  <span class="c1"># feature vectors with character ngrams</span>
  <span class="l l-Scalar l-Scalar-Plain">max_number_of_ngrams</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="intent-featurizer-count-vectors">
<h3>intent_featurizer_count_vectors<a class="headerlink" href="#intent-featurizer-count-vectors" title="Permalink to this headline">Â¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Creates bag-of-words representation of intent features</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">nothing, used as an input to intent classifiers that need bag-of-words representation of intent features (e.g. <code class="docutils literal"><span class="pre">intent_classifier_tensorflow_embedding</span></code>)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">Creates bag-of-words representation of intent features using
<a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">sklearn&#8217;s CountVectorizer</a>. All tokens which consist only of digits (e.g. 123 and 99 but not a123d) will be assigned to the same feature.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If the words in the model language cannot be split by the white-space, a language-specific tokenizer is required in the pipeline before this component (e.g. using <code class="docutils literal"><span class="pre">tokenizer_jieba</span></code> for Chinese language).</p>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Configuration:</th><td class="field-body"><p class="first">See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">sklearn&#8217;s CountVectorizer docs</a>
for detailed description of the configuration parameters</p>
<p>Handling Out-Of-Vacabulary (OOV) words:</p>
<blockquote>
<div><p>Since the training is performed on limited vocabulary data, it cannot be guarantied that during prediction
an algorithm will not encounter an unknown word (a word that were not seen during training).
In order to teach an algorithm how to treat unknown words, some words in training data can be substituted by generic word <code class="docutils literal"><span class="pre">OOV_token</span></code>.
In this case during prediction all unknown words will be treated as this generic word <code class="docutils literal"><span class="pre">OOV_token</span></code>.</p>
<p>For example, one might create separate intent <code class="docutils literal"><span class="pre">outofscope</span></code> in the training data containing messages of different number of <code class="docutils literal"><span class="pre">OOV_token``s</span> <span class="pre">and</span>
<span class="pre">maybe</span> <span class="pre">some</span> <span class="pre">additional</span> <span class="pre">general</span> <span class="pre">words.</span> <span class="pre">Then</span> <span class="pre">an</span> <span class="pre">algorithm</span> <span class="pre">will</span> <span class="pre">likely</span> <span class="pre">classify</span> <span class="pre">a</span> <span class="pre">message</span> <span class="pre">with</span> <span class="pre">unknown</span> <span class="pre">words</span> <span class="pre">as</span> <span class="pre">this</span> <span class="pre">intent</span> <span class="pre">``outofscope</span></code>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This featurizer creates bag-of-words representation by <strong>counting</strong> words, so a number of <a href="#id2"><span class="problematic" id="id3">``</span></a>OOV_token``s might be important.</p>
</div>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">OOV_token</span></code> set a keyword for unseen words; if training data contains <code class="docutils literal"><span class="pre">OOV_token</span></code> as words in some messages,
during prediction the words that were not seen during training will be substituted with provided <code class="docutils literal"><span class="pre">OOV_token</span></code>;
if <code class="docutils literal"><span class="pre">OOV_token=None</span></code> (default behaviour) words that were not seen during training will be ignored during prediction time;</li>
<li><code class="docutils literal"><span class="pre">OOV_words</span></code> set a list of words to be treated as <code class="docutils literal"><span class="pre">OOV_token</span></code> during training; if a list of words that should be treated
as Out-Of-Vacabulary is known, it can be set to <code class="docutils literal"><span class="pre">OOV_words</span></code> instead of manually changing it in trainig data or using custom preprocessor.</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Providing <code class="docutils literal"><span class="pre">OOV_words</span></code> is optional, training data can contain <code class="docutils literal"><span class="pre">OOV_token</span></code> input manually or by custom additional preprocessor.
Unseen words will be substituted with <code class="docutils literal"><span class="pre">OOV_token</span></code> <strong>only</strong> if this token is present in the training data or <code class="docutils literal"><span class="pre">OOV_words</span></code> list is provided.</p>
</div>
</div></blockquote>
<div class="last highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;intent_featurizer_count_vectors&quot;</span>
  <span class="c1"># the parameters are taken from</span>
  <span class="c1"># sklearn&#39;s CountVectorizer</span>
  <span class="c1"># regular expression for tokens</span>
  <span class="s">&quot;token_pattern&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">r&#39;(?u)\b\w\w+\b&#39;</span>
  <span class="c1"># remove accents during the preprocessing step</span>
  <span class="s">&quot;strip_accents&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">None</span>  <span class="c1"># {&#39;ascii&#39;, &#39;unicode&#39;, None}</span>
  <span class="c1"># list of stop words</span>
  <span class="s">&quot;stop_words&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">None</span>  <span class="c1"># string {&#39;english&#39;}, list, or None (default)</span>
  <span class="c1"># min document frequency of a word to add to vocabulary</span>
  <span class="c1"># float - the parameter represents a proportion of documents</span>
  <span class="c1"># integer - absolute counts</span>
  <span class="s">&quot;min_df&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>  <span class="c1"># float in range [0.0, 1.0] or int</span>
  <span class="c1"># max document frequency of a word to add to vocabulary</span>
  <span class="c1"># float - the parameter represents a proportion of documents</span>
  <span class="c1"># integer - absolute counts</span>
  <span class="s">&quot;max_df&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">1.0</span>  <span class="c1"># float in range [0.0, 1.0] or int</span>
  <span class="c1"># set ngram range</span>
  <span class="s">&quot;min_ngram&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>  <span class="c1"># int</span>
  <span class="s">&quot;max_ngram&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>  <span class="c1"># int</span>
  <span class="c1"># limit vocabulary size</span>
  <span class="s">&quot;max_features&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">None</span>  <span class="c1"># int or None</span>
  <span class="c1"># if convert all characters to lowercase</span>
  <span class="s">&quot;lowercase&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>  <span class="c1"># bool</span>
  <span class="c1"># handling Out-Of-Vacabulary (OOV) words</span>
  <span class="c1"># will be converted to lowercase if lowercase is true</span>
  <span class="s">&quot;OOV_token&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">None</span>  <span class="c1"># string or None</span>
  <span class="s">&quot;OOV_words&quot;</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[]</span>  <span class="c1"># list of strings</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="intent-classifier-keyword">
<h3>intent_classifier_keyword<a class="headerlink" href="#intent-classifier-keyword" title="Permalink to this headline">Â¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Simple keyword matching intent classifier.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first"><code class="docutils literal"><span class="pre">intent</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;intent&quot;</span><span class="p">:</span> <span class="p">{</span><span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;greet&quot;</span><span class="p">,</span> <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.98343</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first last">This classifier is mostly used as a placeholder. It is able to recognize <cite>hello</cite> and
<cite>goodbye</cite> intents by searching for these keywords in the passed messages.</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="intent-classifier-mitie">
<h3>intent_classifier_mitie<a class="headerlink" href="#intent-classifier-mitie" title="Permalink to this headline">Â¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">MITIE intent classifier (using a <a class="reference external" href="https://github.com/mit-nlp/MITIE/blob/master/examples/python/text_categorizer_pure_model.py">text categorizer</a>)</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first"><code class="docutils literal"><span class="pre">intent</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;intent&quot;</span><span class="p">:</span> <span class="p">{</span><span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;greet&quot;</span><span class="p">,</span> <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.98343</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first">This classifier uses MITIE to perform intent classification. The underlying classifier
is using a multi class linear SVM with a sparse linear kernel (see <a class="reference external" href="https://github.com/mit-nlp/MITIE/blob/master/mitielib/src/text_categorizer_trainer.cpp#L222">mitie trainer code</a>).</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Configuration:</th><td class="field-body"><div class="first last highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;intent_classifier_mitie&quot;</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="intent-classifier-sklearn">
<h3>intent_classifier_sklearn<a class="headerlink" href="#intent-classifier-sklearn" title="Permalink to this headline">Â¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">sklearn intent classifier</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first"><code class="docutils literal"><span class="pre">intent</span></code> and <code class="docutils literal"><span class="pre">intent_ranking</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;intent&quot;</span><span class="p">:</span> <span class="p">{</span><span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;greet&quot;</span><span class="p">,</span> <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.78343</span><span class="p">},</span>
    <span class="nt">&quot;intent_ranking&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.1485910906220309</span><span class="p">,</span>
            <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;goodbye&quot;</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.08161531595656784</span><span class="p">,</span>
            <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;restaurant_search&quot;</span>
        <span class="p">}</span>
    <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first">The sklearn intent classifier trains a linear SVM which gets optimized using a grid search. In addition
to other classifiers it also provides rankings of the labels that did not &#8220;win&#8221;. The spacy intent classifier
needs to be preceded by a featurizer in the pipeline. This featurizer creates the features used for the classification.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Configuration:</th><td class="field-body"><p class="first">During the training of the SVM a hyperparameter search is run to
find the best parameter set. In the config, you can specify the parameters
that will get tried</p>
<div class="last highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;intent_classifier_sklearn&quot;</span>
  <span class="c1"># Specifies the list of regularization values to</span>
  <span class="c1"># cross-validate over for C-SVM.</span>
  <span class="c1"># This is used with the ``kernel`` hyperparameter in GridSearchCV.</span>
  <span class="l l-Scalar l-Scalar-Plain">C</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[</span><span class="nv">1</span><span class="p p-Indicator">,</span> <span class="nv">2</span><span class="p p-Indicator">,</span> <span class="nv">5</span><span class="p p-Indicator">,</span> <span class="nv">10</span><span class="p p-Indicator">,</span> <span class="nv">20</span><span class="p p-Indicator">,</span> <span class="nv">100</span><span class="p p-Indicator">]</span>
  <span class="c1"># Specifies the kernel to use with C-SVM.</span>
  <span class="c1"># This is used with the ``C`` hyperparameter in GridSearchCV.</span>
  <span class="l l-Scalar l-Scalar-Plain">kernels</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;linear&quot;</span><span class="p p-Indicator">]</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="intent-classifier-tensorflow-embedding">
<h3>intent_classifier_tensorflow_embedding<a class="headerlink" href="#intent-classifier-tensorflow-embedding" title="Permalink to this headline">Â¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Embedding intent classifier</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first"><code class="docutils literal"><span class="pre">intent</span></code> and <code class="docutils literal"><span class="pre">intent_ranking</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;intent&quot;</span><span class="p">:</span> <span class="p">{</span><span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;greet&quot;</span><span class="p">,</span> <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.8343</span><span class="p">},</span>
    <span class="nt">&quot;intent_ranking&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.385910906220309</span><span class="p">,</span>
            <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;goodbye&quot;</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.28161531595656784</span><span class="p">,</span>
            <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;restaurant_search&quot;</span>
        <span class="p">}</span>
    <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first">The embedding intent classifier embeds user inputs and intent labels into the same space. Supervised embeddings are
trained by maximizing similarity between them. This algorithm is based on
the starspace idea from: <a class="reference external" href="https://arxiv.org/abs/1709.03856">https://arxiv.org/abs/1709.03856</a>. However, in this implementation
the <code class="docutils literal"><span class="pre">mu</span></code> parameter is treated differently and additional hidden layers are added together with dropout.
This algorithm also provides similarity rankings of the labels that did not &#8220;win&#8221;.</p>
<p>The embedding intent classifier needs to be preceded by a featurizer in the pipeline.
This featurizer creates the features used for the embeddings.
It is recommended to use <code class="docutils literal"><span class="pre">intent_featurizer_count_vectors</span></code> that can be optionally preceded
by <code class="docutils literal"><span class="pre">nlp_spacy</span></code> and <code class="docutils literal"><span class="pre">tokenizer_spacy</span></code>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If during prediction time a message contains <strong>only</strong> words unseen during training,
and no Out-Of-Vacabulary preprocessor was used,
empty intent <code class="docutils literal"><span class="pre">&quot;&quot;</span></code> is predicted with confidence <code class="docutils literal"><span class="pre">0.0</span></code>.</p>
</div>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Configuration:</th><td class="field-body"><p class="first">If you want to split intents into multiple labels, e.g. for predicting multiple intents or for
modeling hierarchical intent structure, use these flags:</p>
<ul class="simple">
<li><dl class="first docutils">
<dt>tokenization of intent labels:</dt>
<dd><ul class="first last">
<li><code class="docutils literal"><span class="pre">intent_tokenization_flag</span></code> if <code class="docutils literal"><span class="pre">true</span></code> the algorithm will split the intent labels into tokens and use bag-of-words representations for them, default <code class="docutils literal"><span class="pre">false</span></code>;</li>
<li><code class="docutils literal"><span class="pre">intent_split_symbol</span></code> sets the delimiter string to split the intent labels, default <code class="docutils literal"><span class="pre">_</span></code>.</li>
</ul>
</dd>
</dl>
</li>
</ul>
<dl class="docutils">
<dt>The algorithm also has hyperparameters to control:</dt>
<dd><ul class="first last simple">
<li><dl class="first docutils">
<dt>neural network&#8217;s architecture:</dt>
<dd><ul class="first last">
<li><code class="docutils literal"><span class="pre">num_hidden_layers_a</span></code> and <code class="docutils literal"><span class="pre">hidden_layer_size_a</span></code> set the number of hidden layers and their sizes before embedding layer for user inputs;</li>
<li><code class="docutils literal"><span class="pre">num_hidden_layers_b</span></code> and <code class="docutils literal"><span class="pre">hidden_layer_size_b</span></code> set the number of hidden layers and their sizes before embedding layer for intent labels;</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>training:</dt>
<dd><ul class="first last">
<li><code class="docutils literal"><span class="pre">batch_size</span></code> sets the number of training examples in one forward/backward pass, the higher the batch size, the more memory space you&#8217;ll need;</li>
<li><code class="docutils literal"><span class="pre">epochs</span></code> sets the number of times the algorithm will see training data, where <code class="docutils literal"><span class="pre">one</span> <span class="pre">epoch</span></code> = one forward pass and one backward pass of all the training examples;</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>embedding:</dt>
<dd><ul class="first last">
<li><code class="docutils literal"><span class="pre">embed_dim</span></code> sets the dimension of embedding space;</li>
<li><code class="docutils literal"><span class="pre">mu_pos</span></code> controls how similar the algorithm should try to make embedding vectors for correct intent labels;</li>
<li><code class="docutils literal"><span class="pre">mu_neg</span></code> controls maximum negative similarity for incorrect intents;</li>
<li><code class="docutils literal"><span class="pre">similarity_type</span></code> sets the type of the similarity, it should be either <code class="docutils literal"><span class="pre">cosine</span></code> or <code class="docutils literal"><span class="pre">inner</span></code>;</li>
<li><code class="docutils literal"><span class="pre">num_neg</span></code> sets the number of incorrect intent labels, the algorithm will minimize their similarity to the user input during training;</li>
<li><code class="docutils literal"><span class="pre">use_max_sim_neg</span></code> if <code class="docutils literal"><span class="pre">true</span></code> the algorithm only minimizes maximum similarity over incorrect intent labels;</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>regularization:</dt>
<dd><ul class="first last">
<li><code class="docutils literal"><span class="pre">C2</span></code> sets the scale of L2 regularization</li>
<li><code class="docutils literal"><span class="pre">C_emb</span></code> sets the scale of how important is to minimize the maximum similarity between embeddings of different intent labels;</li>
<li><code class="docutils literal"><span class="pre">droprate</span></code> sets the dropout rate, it should be between <code class="docutils literal"><span class="pre">0</span></code> and <code class="docutils literal"><span class="pre">1</span></code>, e.g. <code class="docutils literal"><span class="pre">droprate=0.1</span></code> would drop out <code class="docutils literal"><span class="pre">10%</span></code> of input units;</li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">For <code class="docutils literal"><span class="pre">cosine</span></code> similarity <code class="docutils literal"><span class="pre">mu_pos</span></code> and <code class="docutils literal"><span class="pre">mu_neg</span></code> should be between <code class="docutils literal"><span class="pre">-1</span></code> and <code class="docutils literal"><span class="pre">1</span></code>.</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">There is an option to use linearly increasing batch size. The idea comes from <a class="reference external" href="https://arxiv.org/abs/1711.00489">https://arxiv.org/abs/1711.00489</a>.
In order to do it pass a list to <code class="docutils literal"><span class="pre">batch_size</span></code>, e.g. <code class="docutils literal"><span class="pre">&quot;batch_size&quot;:</span> <span class="pre">[64,</span> <span class="pre">256]</span></code> (default behaviour).
If constant <code class="docutils literal"><span class="pre">batch_size</span></code> is required, pass an <code class="docutils literal"><span class="pre">int</span></code>, e.g. <code class="docutils literal"><span class="pre">&quot;batch_size&quot;:</span> <span class="pre">64</span></code>.</p>
</div>
<p>In the config, you can specify these parameters:</p>
<div class="highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;intent_classifier_tensorflow_embedding&quot;</span>
  <span class="c1"># nn architecture</span>
  <span class="s">&quot;num_hidden_layers_a&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">2</span>
  <span class="s">&quot;hidden_layer_size_a&quot;</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[</span><span class="nv">256</span><span class="p p-Indicator">,</span> <span class="nv">128</span><span class="p p-Indicator">]</span>
  <span class="s">&quot;num_hidden_layers_b&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
  <span class="s">&quot;hidden_layer_size_b&quot;</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[]</span>
  <span class="s">&quot;batch_size&quot;</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[</span><span class="nv">64</span><span class="p p-Indicator">,</span> <span class="nv">256</span><span class="p p-Indicator">]</span>
  <span class="s">&quot;epochs&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">300</span>
  <span class="c1"># embedding parameters</span>
  <span class="s">&quot;embed_dim&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">20</span>
  <span class="s">&quot;mu_pos&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.8</span>  <span class="c1"># should be 0.0 &lt; ... &lt; 1.0 for &#39;cosine&#39;</span>
  <span class="s">&quot;mu_neg&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">-0.4</span>  <span class="c1"># should be -1.0 &lt; ... &lt; 1.0 for &#39;cosine&#39;</span>
  <span class="s">&quot;similarity_type&quot;</span><span class="p p-Indicator">:</span> <span class="s">&quot;cosine&quot;</span>  <span class="c1"># string &#39;cosine&#39; or &#39;inner&#39;</span>
  <span class="s">&quot;num_neg&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">20</span>
  <span class="s">&quot;use_max_sim_neg&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>  <span class="c1"># flag which loss function to use</span>
  <span class="c1"># regularization</span>
  <span class="s">&quot;C2&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.002</span>
  <span class="s">&quot;C_emb&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.8</span>
  <span class="s">&quot;droprate&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.2</span>
  <span class="c1"># flag if to tokenize intents</span>
  <span class="s">&quot;intent_tokenization_flag&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
  <span class="s">&quot;intent_split_symbol&quot;</span><span class="p p-Indicator">:</span> <span class="s">&quot;_&quot;</span>
  <span class="c1"># visualization of accuracy</span>
  <span class="s">&quot;evaluate_every_num_epochs&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>  <span class="c1"># small values may hurt performance</span>
  <span class="s">&quot;evaluate_on_num_examples&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">1000</span>  <span class="c1"># large values may hurt performance</span>
</pre></div>
</div>
<div class="last admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Parameter <code class="docutils literal"><span class="pre">mu_neg</span></code> is set to a negative value to mimic the original
starspace algorithm in the case <code class="docutils literal"><span class="pre">mu_neg</span> <span class="pre">=</span> <span class="pre">mu_pos</span></code> and <code class="docutils literal"><span class="pre">use_max_sim_neg</span> <span class="pre">=</span> <span class="pre">False</span></code>.
See <a class="reference external" href="https://arxiv.org/abs/1709.03856">starspace paper</a> for details.</p>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="intent-entity-featurizer-regex">
<h3>intent_entity_featurizer_regex<a class="headerlink" href="#intent-entity-featurizer-regex" title="Permalink to this headline">Â¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body">regex feature creation to support intent and entity classification</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><code class="docutils literal"><span class="pre">text_features</span></code> and <code class="docutils literal"><span class="pre">tokens.pattern</span></code></td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body">During training, the regex intent featurizer creates a list of <cite>regular expressions</cite> defined in the training data format.
If an expression is found in the input, a feature will be set, that will later be fed into intent classifier / entity
extractor to simplify classification (assuming the classifier has learned during the training phase, that this set
feature indicates a certain intent). Regex features for entity extraction are currently only supported by the
<code class="docutils literal"><span class="pre">ner_crf</span></code> component!
.. note:: There needs to be a tokenizer previous to this featurizer in the pipeline!</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="tokenizer-whitespace">
<h3>tokenizer_whitespace<a class="headerlink" href="#tokenizer-whitespace" title="Permalink to this headline">Â¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body">Tokenizer using whitespaces as a separator</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body">nothing</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body">Creates a token for every whitespace separated character sequence. Can be used to define tokens for the MITIE entity
extractor.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="tokenizer-jieba">
<h3>tokenizer_jieba<a class="headerlink" href="#tokenizer-jieba" title="Permalink to this headline">Â¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Tokenizer using Jieba for Chinese language</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">nothing</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">Creates tokens using the Jieba tokenizer specifically for Chinese
language. For language other than Chinese, Jieba will work as
<code class="docutils literal"><span class="pre">tokenizer_whitespace</span></code>. Can be used to define tokens for the
MITIE entity extractor. Make sure to install Jieba, <code class="docutils literal"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">jieba</span></code>.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Configuration:</th><td class="field-body"><div class="first last highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;tokenizer_jieba&quot;</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="tokenizer-mitie">
<h3>tokenizer_mitie<a class="headerlink" href="#tokenizer-mitie" title="Permalink to this headline">Â¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Tokenizer using MITIE</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">nothing</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">Creates tokens using the MITIE tokenizer. Can be used to define
tokens for the MITIE entity extractor.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Configuration:</th><td class="field-body"><div class="first last highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;tokenizer_mitie&quot;</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="tokenizer-spacy">
<h3>tokenizer_spacy<a class="headerlink" href="#tokenizer-spacy" title="Permalink to this headline">Â¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body">Tokenizer using spacy</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body">nothing</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body">Creates tokens using the spacy tokenizer. Can be used to define
tokens for the MITIE entity extractor.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="ner-mitie">
<h3>ner_mitie<a class="headerlink" href="#ner-mitie" title="Permalink to this headline">Â¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">MITIE entity extraction (using a <a class="reference external" href="https://github.com/mit-nlp/MITIE/blob/master/mitielib/src/ner_trainer.cpp">mitie ner trainer</a>)</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">appends <code class="docutils literal"><span class="pre">entities</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;entities&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="s2">&quot;New York City&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;start&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
                  <span class="nt">&quot;end&quot;</span><span class="p">:</span> <span class="mi">33</span><span class="p">,</span>
                  <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
                  <span class="nt">&quot;entity&quot;</span><span class="p">:</span> <span class="s2">&quot;city&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;extractor&quot;</span><span class="p">:</span> <span class="s2">&quot;ner_mitie&quot;</span><span class="p">}]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first">This uses the MITIE entitiy extraction to find entities in a message. The underlying classifier
is using a multi class linear SVM with a sparse linear kernel and custom features.
The MITIE component does not provide entity confidence values.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Configuration:</th><td class="field-body"><div class="first last highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;ner_mitie&quot;</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="ner-spacy">
<h3>ner_spacy<a class="headerlink" href="#ner-spacy" title="Permalink to this headline">Â¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">spacy entity extraction</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">appends <code class="docutils literal"><span class="pre">entities</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;entities&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="s2">&quot;New York City&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;start&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
                  <span class="nt">&quot;end&quot;</span><span class="p">:</span> <span class="mi">33</span><span class="p">,</span>
                  <span class="nt">&quot;entity&quot;</span><span class="p">:</span> <span class="s2">&quot;city&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
                  <span class="nt">&quot;extractor&quot;</span><span class="p">:</span> <span class="s2">&quot;ner_spacy&quot;</span><span class="p">}]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first last">Using spacy this component predicts the entities of a message. spacy uses a statistical BILUO transition model.
As of now, this component can only use the spacy builtin entity extraction models and can not be retrained.
This extractor does not provide any confidence scores.</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="ner-synonyms">
<h3>ner_synonyms<a class="headerlink" href="#ner-synonyms" title="Permalink to this headline">Â¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Maps synonymous entity values to the same value.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">modifies existing entities that previous entity extraction components found</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">If the training data contains defined synonyms (by using the <code class="docutils literal"><span class="pre">value</span></code> attribute on the entity examples).
this component will make sure that detected entity values will be mapped to the same value. For example,
if your training data contains the following examples:</p>
<div class="highlight-json"><div class="highlight"><pre><span></span><span class="p">[{</span>
  <span class="nt">&quot;text&quot;</span><span class="p">:</span> <span class="s2">&quot;I moved to New York City&quot;</span><span class="p">,</span>
  <span class="nt">&quot;intent&quot;</span><span class="p">:</span> <span class="s2">&quot;inform_relocation&quot;</span><span class="p">,</span>
  <span class="nt">&quot;entities&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="s2">&quot;nyc&quot;</span><span class="p">,</span>
                <span class="nt">&quot;start&quot;</span><span class="p">:</span> <span class="mi">11</span><span class="p">,</span>
                <span class="nt">&quot;end&quot;</span><span class="p">:</span> <span class="mi">24</span><span class="p">,</span>
                <span class="nt">&quot;entity&quot;</span><span class="p">:</span> <span class="s2">&quot;city&quot;</span><span class="p">,</span>
               <span class="p">}]</span>
<span class="p">},</span>
<span class="p">{</span>
  <span class="nt">&quot;text&quot;</span><span class="p">:</span> <span class="s2">&quot;I got a new flat in NYC.&quot;</span><span class="p">,</span>
  <span class="nt">&quot;intent&quot;</span><span class="p">:</span> <span class="s2">&quot;inform_relocation&quot;</span><span class="p">,</span>
  <span class="nt">&quot;entities&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="s2">&quot;nyc&quot;</span><span class="p">,</span>
                <span class="nt">&quot;start&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
                <span class="nt">&quot;end&quot;</span><span class="p">:</span> <span class="mi">23</span><span class="p">,</span>
                <span class="nt">&quot;entity&quot;</span><span class="p">:</span> <span class="s2">&quot;city&quot;</span><span class="p">,</span>
               <span class="p">}]</span>
<span class="p">}]</span>
</pre></div>
</div>
<p class="last">this component will allow you to map the entities <code class="docutils literal"><span class="pre">New</span> <span class="pre">York</span> <span class="pre">City</span></code> and <code class="docutils literal"><span class="pre">NYC</span></code> to <code class="docutils literal"><span class="pre">nyc</span></code>. The entitiy
extraction will return <code class="docutils literal"><span class="pre">nyc</span></code> even though the message contains <code class="docutils literal"><span class="pre">NYC</span></code>. When this component changes an
exisiting entity, it appends itself to the processor list of this entity.</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="ner-crf">
<h3>ner_crf<a class="headerlink" href="#ner-crf" title="Permalink to this headline">Â¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">conditional random field entity extraction</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">appends <code class="docutils literal"><span class="pre">entities</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;entities&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="s2">&quot;New York City&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;start&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
                  <span class="nt">&quot;end&quot;</span><span class="p">:</span> <span class="mi">33</span><span class="p">,</span>
                  <span class="nt">&quot;entity&quot;</span><span class="p">:</span> <span class="s2">&quot;city&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.874</span><span class="p">,</span>
                  <span class="nt">&quot;extractor&quot;</span><span class="p">:</span> <span class="s2">&quot;ner_crf&quot;</span><span class="p">}]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first">This component implements conditional random fields to do named entity recognition.
CRFs can be thought of as an undirected Markov chain where the time steps are words
and the states are entity classes. Features of the words (capitalisation, POS tagging,
etc.) give probabilities to certain entity classes, as are transitions between
neighbouring entity tags: the most likely set of tags is then calculated and returned.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Configuration:</th><td class="field-body"><div class="first last highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;ner_crf&quot;</span>
  <span class="c1"># The features are a ``[before, word, after]`` array with</span>
  <span class="c1"># before, word, after holding keys about which</span>
  <span class="c1"># features to use for each word, for example, ``&quot;title&quot;``</span>
  <span class="c1"># in array before will have the feature</span>
  <span class="c1"># &quot;is the preceding word in title case?&quot;.</span>
  <span class="c1"># Available features are:</span>
  <span class="c1"># ``low``, ``title``, ``word3``, ``word2``, ``pos``,</span>
  <span class="c1"># ``pos2``, ``bias``, ``upper`` and ``digit``</span>
  <span class="l l-Scalar l-Scalar-Plain">features</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[[</span><span class="s">&quot;low&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;title&quot;</span><span class="p p-Indicator">],</span> <span class="p p-Indicator">[</span><span class="s">&quot;bias&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;word3&quot;</span><span class="p p-Indicator">],</span> <span class="p p-Indicator">[</span><span class="s">&quot;upper&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;pos&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;pos2&quot;</span><span class="p p-Indicator">]]</span>

  <span class="c1"># The flag determines whether to use BILOU tagging or not. BILOU</span>
  <span class="c1"># tagging is more rigorous however</span>
  <span class="c1"># requires more examples per entity. Rule of thumb: use only</span>
  <span class="c1"># if more than 100 examples per entity.</span>
  <span class="l l-Scalar l-Scalar-Plain">BILOU_flag</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>

  <span class="c1"># This is the value given to sklearn_crfcuite.CRF tagger before training.</span>
  <span class="l l-Scalar l-Scalar-Plain">max_iterations</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>

  <span class="c1"># This is the value given to sklearn_crfcuite.CRF tagger before training.</span>
  <span class="c1"># Specifies the L1 regularization coefficient.</span>
  <span class="l l-Scalar l-Scalar-Plain">L1_c</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">1.0</span>

  <span class="c1"># This is the value given to sklearn_crfcuite.CRF tagger before training.</span>
  <span class="c1"># Specifies the L2 regularization coefficient.</span>
  <span class="l l-Scalar l-Scalar-Plain">L2_c</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">1e-3</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="ner-duckling">
<span id="section-pipeline-duckling"></span><h3>ner_duckling<a class="headerlink" href="#ner-duckling" title="Permalink to this headline">Â¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Adds duckling support to the pipeline to unify entity types (e.g. to retrieve common date / number formats)</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">appends <code class="docutils literal"><span class="pre">entities</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;entities&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="nt">&quot;end&quot;</span><span class="p">:</span> <span class="mi">53</span><span class="p">,</span>
                  <span class="nt">&quot;entity&quot;</span><span class="p">:</span> <span class="s2">&quot;time&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;start&quot;</span><span class="p">:</span> <span class="mi">48</span><span class="p">,</span>
                  <span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="s2">&quot;2017-04-10T00:00:00.000+02:00&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
                  <span class="nt">&quot;extractor&quot;</span><span class="p">:</span> <span class="s2">&quot;ner_duckling&quot;</span><span class="p">}]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first">Duckling allows to recognize dates, numbers, distances and other structured entities
and normalizes them (for a reference of all available entities
see <a class="reference external" href="https://duckling.wit.ai/#getting-started">the duckling documentation</a>).
Please be aware that duckling tries to extract as many entity types as possible without
providing a ranking. For example, if you specify both <code class="docutils literal"><span class="pre">number</span></code> and <code class="docutils literal"><span class="pre">time</span></code> as dimensions
for the duckling component, the component will extract two entities: <code class="docutils literal"><span class="pre">10</span></code> as a number and
<code class="docutils literal"><span class="pre">in</span> <span class="pre">10</span> <span class="pre">minutes</span></code> as a time from the text <code class="docutils literal"><span class="pre">I</span> <span class="pre">will</span> <span class="pre">be</span> <span class="pre">there</span> <span class="pre">in</span> <span class="pre">10</span> <span class="pre">minutes</span></code>. In such a
situation, your application would have to decide which entity type is be the correct one.
The extractor will always return <cite>1.0</cite> as a confidence, as it is a rule
based system.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Configuration:</th><td class="field-body"><p class="first">Configure which dimensions, i.e. entity types, the <a class="reference internal" href="#section-pipeline-duckling"><span class="std std-ref">duckling component</span></a> to extract.
A full list of available dimensions can be found in the <a class="reference external" href="https://duckling.wit.ai/">duckling documentation</a>.</p>
<div class="last highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;ner_duckling&quot;</span>
  <span class="c1"># dimensions to extract</span>
  <span class="l l-Scalar l-Scalar-Plain">dimensions</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;time&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;number&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;amount-of-money&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;distance&quot;</span><span class="p p-Indicator">]</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="creating-new-components">
<h2>Creating new Components<a class="headerlink" href="#creating-new-components" title="Permalink to this headline">Â¶</a></h2>
<p>You can create a custom Component to perform a specific task which NLU doesn&#8217;t currently offer (e.g. sentiment analysis).
A glimpse into the code of <code class="docutils literal"><span class="pre">rasa_nlu.components.Component</span></code> will reveal
which functions need to be implemented to create a new component.
You can add these to your pipeline by adding the module path to your pipeline, e.g. if you have a module called <code class="docutils literal"><span class="pre">sentiment</span></code>
containing a <code class="docutils literal"><span class="pre">SentimentAnalyzer</span></code> class:</p>
<blockquote>
<div><div class="highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;sentiment.SentimentAnalyzer&quot;</span>
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="component-lifecycle">
<h2>Component Lifecycle<a class="headerlink" href="#component-lifecycle" title="Permalink to this headline">Â¶</a></h2>
<p>Every component can implement several methods from the <code class="docutils literal"><span class="pre">Component</span></code> base class; in a pipeline these different methods
will be called in a specific order. Lets assume, we added the following pipeline to our config:
<code class="docutils literal"><span class="pre">&quot;pipeline&quot;:</span> <span class="pre">[&quot;Component</span> <span class="pre">A&quot;,</span> <span class="pre">&quot;Component</span> <span class="pre">B&quot;,</span> <span class="pre">&quot;Last</span> <span class="pre">Component&quot;]</span></code>.
The image shows the call order during the training of this pipeline :</p>
<img alt="_images/component_lifecycle.png" src="_images/component_lifecycle.png" />
<p>Before the first component is created using the <code class="docutils literal"><span class="pre">create</span></code> function, a so called <code class="docutils literal"><span class="pre">context</span></code> is created (which is
nothing more than a python dict). This context is used to pass information between the components. For example,
one component can calculate feature vectors for the training data, store that within the context and another
component can retrieve these feature vectors from the context and do intent classification.</p>
<p>Initially the context is filled with all configuration values, the arrows in the image show the call order
and visualize the path of the passed context. After all components are trained and persisted, the
final context dictionary is used to persist the model&#8217;s metadata.</p>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="evaluation.html" class="btn btn-neutral float-right" title="Evaluation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="languages.html" class="btn btn-neutral" title="Language Support" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Rasa Technologies GmbH.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        <span class="fa fa-book"> Other Versions</span>
        v: master
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        <dl>
            <dt>Branches</dt>
            <dd><a href="pipeline.html">master</a></dd>
        </dl>
    </div>
</div>


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'10.12.3+project_manager.worker_interfaces',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
  
 
<!-- Global Site Tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-87333416-1"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments)};
gtag('js', new Date());

gtag('config', 'UA-87333416-1');
</script>
<script type="text/javascript" src="//script.crazyegg.com/pages/scripts/0074/3851.js" async="async"></script>


</body>
</html>